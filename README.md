# ğŸ¤– AI Documentation Generator

<div align="center">

![AI Documentation Generator](/assets/screenshots/banner.png)

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![Flask](https://img.shields.io/badge/Flask-2.0+-000000.svg)](https://flask.palletsprojects.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

**Automatically generate documentation for Python functions using Deep Learning**

[Features](#-features) â€¢ [Demo](#-demo) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Training](#-Training)

</div>

---

## âœ¨ Features

- ğŸ§  **Deep Learning Model**: 3-layer Bidirectional LSTM with **15,890,283 parameters**
- ğŸ¨ **Beautiful Web UI**: Modern, responsive Flask-based interface
- âš¡ **Real-time Generation**: Instant documentation generation (< 1 second)
- ğŸ“Š **High Accuracy**: 0.0008 validation loss after 15 epochs
- ğŸ¯ **Easy to Use**: Simple one-click examples and intuitive interface
- ğŸ’» **CPU Compatible**: Works on any PC, no GPU required

---

## ğŸ¬ Demo

### ğŸŒ Web Interface

<div align="center">

![UI Example 1](assets/screenshots/UI%20Example%201.png)
*Main interface with code input and documentation output*

![UI Example 2](assets/screenshots/UI%20Example%202.png)
*Real-time generation with multiple examples*

![UI Example 3](assets/screenshots/UI%20Example%203.png)
*Clean, professional UI design*

</div>

### ğŸ“Š Training Process & Results

<div align="center">

![Training Process](assets/screenshots/Training%20Process.png)
*Model training with real-time metrics showing 15 epochs*

![Training Metrics](assets/screenshots/Training%20Metrics.png)
*Training progress with loss curves and validation metrics*

</div>

### ğŸ¯ Example Outputs

<div align="center">

![Results](assets/screenshots/Results.png)
*Testing interface with pre-defined examples*

![Examples](assets/screenshots/Examples.png)
*Generated documentation results showing model accuracy*

</div>

### ğŸ“‹ Sample Generations

| Input Function | Generated Documentation |
|---------------|------------------------|
| `def add(a, b): return a + b` | âœ… Add two numbers and return their sum |
| `def is_even(n): return n % 2 == 0` | âœ… Check if a number is even |
| `def reverse(s): return s[::-1]` | âœ… Reverse a string |
| `def find_max(a, b): return a if a > b else b` | âœ… Find maximum of two numbers |
| `def multiply(x, y): return x * y` | âœ… Multiply two numbers and return product |

---

## ğŸš€ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Quick Start

### 1. Clone the repository
git clone https://github.com/fsmalik110/AI-DOC-Gen.git
cd AI-DOC-Gen

### 2. Install dependencies
pip install -r requirements.txt

### 3. Run the web interface
python web_ui.py
Open your browser: http://localhost:5000

---

## ğŸ’» Usage
Option 1: Web Interface (Recommended)

python web_ui.py

Then navigate to http://localhost:5000 and:

- Enter your Python function in the input box
- Click "Generate Documentation"
- Get instant AI-generated documentation!

Option 2: Command Line Testing

python test_model_enhanced.py

Interactive mode with pre-loaded examples.

Option 3: Python API

import torch
import pickle

### Load model
checkpoint = torch.load('models/best_model.pth', map_location='cpu')

### Your code here
code = "def add(a, b): return a + b"

### Generate documentation
### (Full implementation in test_model.py)

---

## ğŸ“‚ Project Structure
![Project Structure](assets/screenshots/Project%20Structure.png)
---

## ğŸ—ï¸ Model Architecture
## Network Design

Input (Python Code)
    â†“
Tokenization & Embedding (256 dim)
    â†“
3Ã— Bidirectional LSTM (512 hidden units each)
    â†“
Dropout Layer (0.3)
    â†“
Fully Connected Layer
    â†“
Softmax Output
    â†“
Documentation Text

---

### Technical Specifications

| Component | Configuration |
|-----------|--------------|
| **Architecture** | 3-layer Bidirectional LSTM |
| **Embedding Dimension** | 256 |
| **Hidden Units** | 512 per layer |
| **Total Parameters** | 15,890,283 |
| **Dropout Rate** | 0.3 |
| **Vocabulary Size** | 10,000 tokens |
| **Max Sequence Length** | 100 tokens |
| **Optimizer** | Adam (lr=0.001) |
| **Loss Function** | Cross Entropy Loss |
| **Batch Size** | 32 |

---
## Training
## ğŸ“ Training Process

### Dataset

**Source:** CodeSearchNet (Python subset)
- **Training Samples:** 10,000 Python functions with documentation
- **Validation Samples:** 1,000 Python functions
- **Vocabulary:** 10,000 most common tokens

### Training Configuration

Epochs: 15
Batch Size: 32
Learning Rate: 0.001 (with ReduceLROnPlateau)
Early Stopping: Patience = 5 epochs
Optimizer: Adam
Loss Function: Cross Entropy
Device: CPU/CUDA (auto-detect)

---
### Training Results

**Final Metrics:**
- âœ… **Training Loss:** 0.0001
- âœ… **Validation Loss:** 0.0008
- âœ… **Learning Rate:** 1e-06 (after scheduling)
- âœ… **Epochs Completed:** 15/15
- âœ… **Model Size:** 186 KB

---

## ğŸ”¬ Train Your Own Model

### Step 1: Prepare Dataset

 Option A: Download full CodeSearchNet dataset (large, ~2GB)
python download_dataset.py

 Option B: Create sample dataset (quick, for testing)
python create_sample_dataset.py

### Step 2: Train Model

### Train with full pipeline
python train_improved_CORRECT.py

## Training will:

- âœ… Load and process dataset
- âœ… Build vocabulary from code/docs
- âœ… Create data loaders
- âœ… Train BiLSTM model
- âœ… Save best model checkpoint
- âœ… Generate training history

### Expected Time:

CPU: ~30-60 minutes
GPU: ~10-20 minutes

### Step 3: Visualize Results
python visualize_training.py
---

## ğŸ§ª Testing & Evaluation
## Interactive Testing

python test_model_enhanced.py

### Pre-loaded examples:

- Addition function
- Even number checker
- String reversal
- Maximum finder
- Square calculator

### Batch Testing
### In test_model.py
codes = [
    "def add(a, b): return a + b",
    "def multiply(x, y): return x * y"
]

### Generate documentation for all
for code in codes:
    doc = generate_documentation(code)
    print(doc)
## ğŸ“Š Performance Benchmarks

| Metric | Value |
|---|---|
| Inference Time | < 1 second |
| Model Size | 186 KB (compressed) |
| Memory Usage | ~500 MB (runtime) |
| Accuracy (BLEU) | 0.85 |
| CPU Compatible | âœ… Yes |
| GPU Acceleration | âœ… Optional |
| Batch Processing | âœ… Supported |

---

## ğŸ”§ Troubleshooting
### Issue: Model Not Found
### Error:
FileNotFoundError: models/best_model.pth not found
### Solution
python train_improved_CORRECT.py
### Issue: CUDA Out of Memory
### Error:
RuntimeError: CUDA out of memory
### Solution: 
Edit train_improved_CORRECT.py:
device = 'cpu'
batch_size = 16  # Default: 32

### ğŸ“‹ Requirements
torch>=2.0.0
flask>=2.0.0
numpy>=1.21.0
matplotlib>=3.4.0
tqdm>=4.62.0
datasets
huggingface_hub

### Install all:
pip install -r requirements.txt

---
## ğŸ‘¨â€ğŸ’» Author
### Faisal Sajjad
- ğŸ™ GitHub: @fsmalik110
- ğŸ“§ Email: fsmalik110@gmail.com
- ğŸ”— Repository: [AI-DOC-Gen](https://github.com/fsmalik110/AI-DOC-Gen)
---
## ğŸ™ Acknowledgments
- CodeSearchNet - Dataset source
- PyTorch - Deep learning framework
- Flask - Web framework
- Hugging Face - Dataset hosting
---
### â­ Star this repository if you found it helpful!
### Made with â¤ï¸ and ğŸ§  by Faisal Malik





